---
title: "Final Project"
author: "Wayne Wang"
date: "Saturday, December 12, 2016"
output: html_document
---
### This goal of this project is to show the sentiment analysis of 30,000 tweets about 2016 MLB World Series collected from New York, Toronto, and California. What we want to show is how many people are pro-Cubs or pro-Indians. The locations from which tweets were collected are purposely set to be non-Chicago Area and non-Cleveland area to avoid bias. This R markdown shows how the tweets were collected and processed. The results of the sentiment analysis will be interactively demonstrated in the Shiny app associated with this file. 

### Note: If you encounter an issue while running the app with an error message "Error in as.vector: attempt to apply non-function", please delete your ggplot2 and ggmap packages, re-install them, and re-start your R session. 

### Setting up twitter connections 
```{r , echo=FALSE}
library(twitteR)
library(ROAuth)
library(dplyr)
library(tidyr)
library(tidytext)

api_key <-   "co5L56nasutwm2HI0QTM6RJ3f"
api_secret <- "qjrg5kpRZNBT8IyjL7ewVvc9W6wd6YjRQ5TXDFd2Jq5NzXvvcV"
access_token <- "3611708723-7Z9Xg6N7XDzosyn44eyCFoceE3Dmc3WckL9Jb8M"
access_token_secret <- "h5eNHkIdcYG2vQsZW1Vrl7xNvBe0N5eiSzwMtMnLUYf2s"

setup_twitter_oauth(api_key, api_secret, access_token, access_token_secret)
```


### Extract tweets from California
```{r}
# search tweets talking about cubs
search.string <- "#cubs"
no.of.tweets <- 5000
geocode.string <- '36.7783,-119.4179, 100mi'

cubs <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
cubs.df <- twListToDF(cubs)
cubs.df$team <- "cubs"

# search tweets talking about indians
search.string <- "#indians"

indians <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
indians.df  <- twListToDF(indians)
indians.df$team <- "indians" 

# Combine tweets df
tweets.df <- rbind(cubs.df,indians.df)
```


### Managing tweet texts into a tidy form (Word count)
```{r}
tidy_tweet <- tweets.df %>%
  mutate(tweetID = row_number()) %>%
  unnest_tokens(word, text)

# sentiment analysis
bing <- get_sentiments("bing")

tweet_sentiment_ca <- tidy_tweet %>%
  inner_join(bing) %>%
  count(tweetID, index =  team , sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

tweet_sentiment_ca$loc <- 'California'
  
```


### Extract tweets from New York
```{r}
# search tweets talking about cubs
search.string <- "#cubs"
no.of.tweets <- 5000
geocode.string <- '40.7128,-74.0059, 100mi'

cubs <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
cubs.df <- twListToDF(cubs)
cubs.df$team <- "cubs"

# search tweets talking about indians
search.string <- "#indians"

indians <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
indians.df  <- twListToDF(indians)
indians.df$team <- "indians" 

# Combine tweets df
tweets.df <- rbind(cubs.df,indians.df)
```


### Managing tweet texts into a tidy form
```{r}
tidy_tweet <- tweets.df %>%
  mutate(tweetID = row_number()) %>%
  unnest_tokens(word, text)

# sentiment analysis
tweet_sentiment_ny <- tidy_tweet %>%
  inner_join(bing) %>%
  count(tweetID, index =  team , sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
  
tweet_sentiment_ny$loc <- 'New York'

```


### Extract tweets from Tornoto
```{r}
# search tweets talking about cubs
search.string <- "#cubs"
no.of.tweets <- 5000
geocode.string <- '43.6532,-79.3832, 100mi'

cubs <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
cubs.df <- twListToDF(cubs)
cubs.df$team <- "cubs"

# search tweets talking about indians
search.string <- "#indians"

indians <- searchTwitter(search.string, n=no.of.tweets, lang="en", geocode = geocode.string)
indians.df  <- twListToDF(indians)
indians.df$team <- "indians" 

# Combine tweets df
tweets.df <- rbind(cubs.df,indians.df)
```


### Managing tweet texts into a tidy form
```{r}
tidy_tweet <- tweets.df %>%
  mutate(tweetID = row_number()) %>%
  unnest_tokens(word, text)

# sentiment analysis
tweet_sentiment_toronto <- tidy_tweet %>%
  inner_join(bing) %>%
  count(tweetID, index =  team , sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)
  
tweet_sentiment_toronto$loc <- 'Toronto'

```


### Combine all tweeter data
```{r}
tweet_sentiment <- rbind(tweet_sentiment_ny,tweet_sentiment_ca,tweet_sentiment_toronto)

# save tweet_sentiment for Shiny app use
save(tweet_sentiment,file="tweet_sentiment.Rdata")
```

### Create lat/long data for map
```{r}
#CA:???36.7783,-119.4179
#NY:  40.7128,-74.0059
#TOR: 43.6532,-79.3832
lon <- c(-119.4179, -74.0059, -79.3832)
lat <- c(36.7783, 40.7128, 43.6532)
locname <- c("California", "New York", "Toronto")
loc <- data.frame(lat, lon, locname)

save(loc, file = "location.Rdata")
```

